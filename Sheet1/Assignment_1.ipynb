{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NNTI Assignment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "@authors:  Mhd Jawad Al Rahwanji , Christian Singer\n",
    "@ID:  7038980, 7039059\n",
    "@email: mhal00002@stud.uni-saarland.de, chsi00002@stud.uni-saarland.de"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let $A\\in\\mathbb{R}^{m\\times n}, B\\in\\mathbb{R}^{n\\times p}$ and $B\\in\\mathbb{R}^{p\\times q}$ then $L\\equiv AB\\in\\mathbb{R}^{m\\times p}\\text{ and }S\\equiv (AB)C = RC\\in\\mathbb{R}^{m\\times q}$\n",
    "### with $r_{i k}=\\sum_{l=1}^n a_{i l} \\cdot b_{l k}$ and $s_{i j}=\\sum_{k=1}^p r_{i k} \\cdot c_{k j}$, using the distributive law for addition and multiplication this yields\n",
    "### $s_{i j}=\\sum_{k=1}^p (\\sum_{l=1}^n a_{i l} \\cdot b_{l k}) \\cdot c_{k j} = \\sum_{k=1}^p \\sum_{l=1}^n (a_{i l} \\cdot b_{l k}) \\cdot c_{k j} = \\sum_{k=1}^p \\sum_{l=1}^n a_{i l} (\\cdot b_{l k} \\cdot c_{k j}) = \\sum_{l=1}^n \\sum_{k=1}^p a_{i l} (\\cdot b_{l k} \\cdot c_{k j})$\n",
    "### which shows the associativity of matrix multiplication."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Exercise 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Custom dataset class for loading image datasets.\n",
    "class CustomImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Create a pytorch dataset containing images with corresponding labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, labels_dir: str, img_dir: str):\n",
    "        super().__init__()\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = pd.read_csv(labels_dir, header=None)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        return image, label\n",
    "\n",
    "# Custom DataLoader to load our dataset.\n",
    "class CustomImageDataLoader(DataLoader):\n",
    "    \"\"\"\n",
    "    Create a pytorch dataloader for the custom image dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels_dir: str, img_dir: str, batch_size: int):\n",
    "        self.dataset = CustomImageDataset(labels_dir, img_dir)\n",
    "        super().__init__(\n",
    "            self.dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Define collate function\n",
    "def collate_fn(batch: List[torch.Tensor]) -> Tuple[torch.Tensor, List[int]]:\n",
    "    \"\"\"\n",
    "    Resize each axis of the image, such that the total image is 20% smaller.\n",
    "    \"\"\"\n",
    "    # https://stackoverflow.com/questions/29139350/difference-between-ziplist-and-ziplist\n",
    "    images, labels = zip(*batch)\n",
    "    # Unsqueezing the images simulates a minibatch of size 1.\n",
    "    images = [\n",
    "        F.interpolate(image.unsqueeze(0), scale_factor=pow(0.8, 0.5)).squeeze(0)\n",
    "        for image in images\n",
    "    ]\n",
    "    return torch.stack(images), labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 10\n",
      "Size of image 0: torch.Size([3, 512, 512]), label: 0\n",
      "Size of image 1: torch.Size([3, 512, 512]), label: 0\n",
      "Size of image 2: torch.Size([3, 512, 512]), label: 0\n",
      "Size of image 3: torch.Size([3, 512, 512]), label: 0\n",
      "Size of image 4: torch.Size([3, 512, 512]), label: 0\n",
      "Size of image 5: torch.Size([3, 512, 512]), label: 1\n",
      "Size of image 6: torch.Size([3, 512, 512]), label: 1\n",
      "Size of image 7: torch.Size([3, 512, 512]), label: 1\n",
      "Size of image 8: torch.Size([3, 512, 512]), label: 1\n",
      "Size of image 9: torch.Size([3, 512, 512]), label: 1\n",
      "Labels: (1, 0, 0, 1)\n",
      "Size of image batch: torch.Size([4, 3, 457, 457])\n"
     ]
    }
   ],
   "source": [
    "# The code in the cells below lets you verify that our implementations fulfill the criteria specified on the exercise sheet.\n",
    "dataset = CustomImageDataset(labels_dir=\"data\\\\labels.csv\", img_dir=\"data\\\\images\")\n",
    "\n",
    "# Proof that dataset has a length.\n",
    "print(f\"Length of dataset: {len(dataset)}\")\n",
    "\n",
    "# Proof that dataset is iterable.\n",
    "for i, x in enumerate(dataset):\n",
    "    print(f\"Size of image {i}: {x[0].shape}, label: {x[1]}\")\n",
    "\n",
    "# Proof that dataset is a valid input to DataLoader.\n",
    "dataloader = CustomImageDataLoader(labels_dir=\"data\\\\labels.csv\", img_dir=\"data\\\\images\", batch_size=4)\n",
    "image, label = next(iter(dataloader))\n",
    "print(f\"Labels: {label}\")\n",
    "# Proof that images have been resized to 80% of their original size.\n",
    "print(f\"Size of image batch: {image.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
